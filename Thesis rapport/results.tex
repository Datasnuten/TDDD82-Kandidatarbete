\chapter{Validated Results}
\label{cha:results}

To demonstrate the geo-based media player, we went out and did some recordings to test the functionalities we designed and implemented in this thesis. We went to “Blåa havet” in front of Kårallen, located at Linköping University, where some students were promoting an upcoming event with some activities. We found that this was a suitable point of interest to record from different angles for our testing case. As we only had two cameras available at the time we made three sets of recordings consisting of two recordings each, with each set displaying the same scene from two different locations and angles at the same time. The desired outcomes of this test was to prove the accuracy of the relative placement algorithm and, within the interface, be able to swap between the recordings to view the same object at one point in time from different angles.

\section{Position Algorithm}
\label{sec:positionalgorithm}

To demonstrate the accuracy of the relative placement of geographical points in the interface, we noted the GPS-coordinates and angles at the used recording locations. We then input the coordinates into Google Maps as seen in Figure \ref{fig:googlemaps}, which is used here as a reference to prove the accuracy of our placement algorithm. We also input the same latitude and longitude values into our interface along with the angles used in the recordings to test our algorithm for a few objects. We later input another larger set of coordinates into the interface including many objects to load test the algorithm. Figure \ref{fig:GeomapVsGoogleLessThan10objects} shows the comparison between the algorithm's object placement and the Google Maps reference with the coordinates used in the test case and Figure \ref{fig:GeomapVsGoogleMoreThan10objects} shows a similar comparison in the algorithm's load test. In these figures the displayed yellow stars represents Google Maps' placement of the given coordinates while the arrow-dots represents the same respective placement of the coordinates as received from the interface.


\begin{figure}[ht!]
\begin{center}
	\includegraphics[scale=0.64]{Google_Maps.png}
	\caption{Google Maps view of the Streaming locations}
	\label{fig:googlemaps}
\end{center}
\end{figure}

\begin{figure}
\begin{subfigure}[b]{0.5\textwidth}
        \includegraphics[width=\textwidth]{GeomapVsGooglemindrean10.png}
        \caption{Comparison with Google Maps in the test case}
        \label{fig:GeomapVsGoogleLessThan10objects}
    \end{subfigure}\hfill 
    \hspace{3px}
    \begin{subfigure}[b]{0.51\textwidth}
        \includegraphics[width=\textwidth]{GeomapVsGooglefleran10.png}
        \caption{Comparison with Google Maps in the load test}
        \label{fig:tiger}
    \label{fig:GeomapVsGoogleMoreThan10objects}
    \end{subfigure}
	\caption{Geo-map compared to google map using equirectangular algorithm}
	\label{fig:GeomapVsGoogleWithLessThan10objects}
\end{figure}

The placement of the arrow points in Figure \ref{fig:GeomapVsGoogleLessThan10objects} is almost an exact match to the Google Maps reference stars for the respective coordinates, at least in terms off relativity. There is a slight difference between interface's placement and the reference in this figure and the reason for this is that our method for rotating the arrow points is not optimal. The default and only way of rotating a graphical object provided by our programming tools is to rotate the object around its top-left corner. Due to this we added some functionality to this existing rotation function to make the objects rotate around its center instead. Because this rotation code is not optimal there is a very slight deviation from its supposed placement. With the load test however, we did not angle the arrow points as shown in Figure \ref{fig:GeomapVsGoogleMoreThan10objects}. Because the suboptimal rotation function does not take place here the algorithm's relative placement is exactly on point with its reference.

This would prove the accuracy of our relative placement of the geographical points, albeit with a slightly better precision if the objects are not rotated. The rotation function will be further discussed in \textit{Chapter \ref{cha:discussion}}.

\section{Geo-based Streaming}
\label{sec:geobasedstreaming}

As we have mentioned before our implementations is as shown in Figure \ref{fig:gpsinterface}, where we have a button that opens the geographical map, a circle that represents a “map” and arrows pointing in a direction that represents streamers and videos. When a user selects a video the arrow is highlighted and that video is then played. In our test case, we set up two cameras at a time and did recordings of 90 seconds each. In these videos we captured many people doing various activities. There were people jumping the trampoline, using hoverboards, walking and biking around. When we input these three sets of two recordings each into our media player, we could swap between the two recordings of each set and watch these same events unfold from different positions and angles. In Figures \ref{fig:testview1A} and \ref{fig:testview2A} two different recordings are selected and they show the same event where, for example, the guy inside the red circle in the pictures are hoverboarding in front of the red shirt guy the same time of the videos. If we look at Figures \ref{fig:testview1B} and \ref{fig:testview2B} they show the geo-map interface of the views. Both interfaces shows that a different stream object is highlighted when a different view is shown. This would prove the desired functionality of where the user can display the same events unfold from different geographical positions and angles.

\begin{figure}
\begin{subfigure}[b]{0.5\textwidth}
 	\includegraphics[width=\linewidth]{Hoverboard_1.png}
  	\caption{Test view 1 without the interface visible}\label{fig:testview1A}
    \end{subfigure}\hfill 
    \hspace{3px}
    \begin{subfigure}[b]{0.5\textwidth}
	\includegraphics[width=\linewidth]{Hoverboard1medmap.png}
  	\caption{Test view 1 with the interface visible}\label{fig:testview1B}
    \end{subfigure}
	\caption{Test view 1}
	\label{fig:testview1}
\end{figure}

\begin{figure}
\begin{subfigure}[b]{0.5\textwidth}
 	\includegraphics[width=\linewidth]{Hoverboard_2.png}
  	\caption{Test view 2 without the interface visible}\label{fig:testview2A}
    \end{subfigure}\hfill 
    \hspace{3px}
    \begin{subfigure}[b]{0.5\textwidth}
	 \includegraphics[width=\linewidth]{Hoverboard2medmap.png}
 	\caption{Test view 2 with the interface visible}\label{fig:testview2B}
    \end{subfigure}
	\caption{Test view 2}
	\label{fig:testview2}
\end{figure}

\section{Consistency with On-demand Switching}
Even though prefetching is not implemented we can still test the consistency of the on-demand switching, looking at the time it takes to switch between different videos on-demand. This test was done by clicking between different stream objects on the interface and measuring the time it takes from when the user clicks a stream until the stream is displayed and played in the media player. In the test we measured three different parts of this process; the time between the user clicks the stream object until the stream starts to download, the time it takes for the stream to be downloaded and ready to play and the time between this download has completed until the stream actually starts playing in the media player. Finally, we included a fourth measurement of the total time between a switch between two streams. Switching between different videos was done 200 times and four graphical representations of how long each of these processes took is shown in Figures \ref{fig:click-time} to \ref{fig:start-time}. Every part (a) of the figures represents the frequency for a certain time interval in that figure's and process’ measurement segment. Every part (b) of the figures shows the Cumulative Distribution Function (CDF) for that specific measurement, which is the probability that a certain time \textit{x} will occur.

We can see from the CDF graph in Figure \ref{fig:cdf4} that the probability that a video switch take less than 140 milliseconds is around 60 $\%$ and that the probability for a video switch under 160 milliseconds is around 83 $\%$. This means that a video switch will unlikely take more than 160 milliseconds or even more than 200 milliseconds.  The average time it took to switch is roughly 150 milliseconds, or 148 milliseconds to be precise. The median is 137 milliseconds and the standard deviation is around 37 $\%$.

The times for switching is likely a bit faster than shown in Figure \ref{fig:start-time} because of how checking the time is done. The time starts when the object is clicked and a new advertisement is created. After that a new media player is created and  the URL will be retrieved through the AMS 5. The URL will then be sent to the plug-in script and then called by the \textit{AdvertisementPluginInfo} class. The URL is then prebuffered a little bit before the video is ready to be played in which the timer will stop. The prebuffering time is shown in Figure \ref{fig:load-time}. If prebuffering of the video can be done in a more efficient way with optimized prefetching similiar to what is done in the project \cite{optimizedstreaming} the time would have been a lot faster. 

This test is done from another computer which did not host AMS 5 which means that it had to send requests of the streams to the computer hosting the AMS 5 in order to receive the videos. Keep in mind if this consistency test were done on a different performing setup with another set of computers and connections, this result would likely vary.

\hspace*{-2cm}
\begin{figure}[!ht]
\begin{subfigure}[b]{0.5\textwidth}
 	\includegraphics[width=\linewidth]{Histogram_Click-time.png}
  	\caption{Histogram}\label{fig:histogram}
    \end{subfigure}\hfill 
    \hspace{3px}
    \begin{subfigure}[b]{0.5\textwidth}
	 \includegraphics[width=\linewidth]{CDF_Click-time.png}
 	\caption{CDF}\label{fig:cdf}
    \end{subfigure}
	\caption{Time between click to download}
	\label{fig:click-time}
\end{figure}

\begin{figure}
\begin{subfigure}[b]{0.5\textwidth}
 	\includegraphics[width=\linewidth]{Histogram_Load-time.png}
  	\caption{Histogram}\label{fig:histogram2}
    \end{subfigure}\hfill 
    \hspace{3px}
    \begin{subfigure}[b]{0.5\textwidth}
	 \includegraphics[width=\linewidth]{CDF_Load-time.png}
 	\caption{CDF}\label{fig:cdf2}
    \end{subfigure}
	\caption{Time to download}
	\label{fig:load-time}
\end{figure}

\begin{figure}
\begin{subfigure}[b]{0.5\textwidth}
 	\includegraphics[width=\linewidth]{Histogram_Play-time.png}
  	\caption{Histogram}\label{fig:histogram3}
    \end{subfigure}\hfill 
    \hspace{3px}
    \begin{subfigure}[b]{0.5\textwidth}
	 \includegraphics[width=\linewidth]{CDF_Play-time.png}
 	\caption{CDF}\label{fig:cdf3}
    \end{subfigure}
	\caption{Time between download to play}
	\label{fig:play-time}
\end{figure}

\begin{figure}
\begin{subfigure}[b]{0.5\textwidth}
 	\includegraphics[width=\linewidth]{Histogram_Start-time.png}
  	\caption{Histogram}\label{fig:histogram4}
    \end{subfigure}\hfill 
    \hspace{3px}
    \begin{subfigure}[b]{0.5\textwidth}
	 \includegraphics[width=\linewidth]{CDF_Start-time.png}
 	\caption{CDF}\label{fig:cdf4}
    \end{subfigure}
	\caption{Total time from click to play}
	\label{fig:start-time}
\end{figure}